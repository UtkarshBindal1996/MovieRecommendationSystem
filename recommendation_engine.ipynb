{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c645ed82-8ee0-4592-9096-a92a5ae07b74",
   "metadata": {},
   "source": [
    "# Movie Mate: Find Your Next Cinematic Match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f0ee6d-11da-4c4b-902b-43acdd96a4d4",
   "metadata": {},
   "source": [
    "## Objective: Build and evaluate recommendation engines to predict user movie preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad97e609-9491-4826-a680-bbfd97b45899",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Ditch the endless scrolling! Our data-powered engine finds your next cinematic soulmate based on your unique movie taste.\n",
    "\n",
    "Our objective is to leverage the power of data science to build intelligent recommendation engines that can predict which superhero movies you'll enjoy the most. By analyzing your movie preferences and incorporating the \"Batman vs. Superman\" theme, we aim to create a personalized recommendation experience that caters to your specific tastes.\n",
    "\n",
    "The cornerstone of our recommendation system is the MovieLens dataset. This renowned dataset provides a treasure trove of user ratings for countless movies across various genres. The richness of this data allows us to understand user preferences and identify patterns that can be harnessed for movie recommendations.\n",
    "\n",
    "Get ready to embark on a thrilling journey as we explore the intersection of data science and superhero fandom!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb8127d-1ca0-4ce9-92b7-bd1bb9ef4bd0",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f3a298-63c7-47b9-a0be-d38dc4d3632b",
   "metadata": {},
   "source": [
    "#### Looking at the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8c3f18-feb1-4cf8-b749-bb1bce46dff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in each data source:\n",
      "File name: tag\n",
      "   userId  movieId            tag            timestamp\n",
      "0      18     4141    Mark Waters  2009-04-24 18:19:40\n",
      "1      65      208      dark hero  2013-05-10 01:41:18\n",
      "2      65      353      dark hero  2013-05-10 01:41:19\n",
      "3      65      521  noir thriller  2013-05-10 01:39:43\n",
      "4      65      592      dark hero  2013-05-10 01:41:18\n",
      "File name: rating\n",
      "   userId  movieId  rating            timestamp\n",
      "0       1        2     3.5  2005-04-02 23:53:47\n",
      "1       1       29     3.5  2005-04-02 23:31:16\n",
      "2       1       32     3.5  2005-04-02 23:33:39\n",
      "3       1       47     3.5  2005-04-02 23:32:07\n",
      "4       1       50     3.5  2005-04-02 23:29:40\n",
      "File name: movie\n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "File name: link\n",
      "   movieId  imdbId   tmdbId\n",
      "0        1  114709    862.0\n",
      "1        2  113497   8844.0\n",
      "2        3  113228  15602.0\n",
      "3        4  114885  31357.0\n",
      "4        5  113041  11862.0\n",
      "File name: genome_tags\n",
      "   tagId           tag\n",
      "0      1           007\n",
      "1      2  007 (series)\n",
      "2      3  18th century\n",
      "3      4         1920s\n",
      "4      5         1930s\n",
      "File name: genome_scores\n",
      "   movieId  tagId  relevance\n",
      "0        1      1    0.02500\n",
      "1        1      2    0.02500\n",
      "2        1      3    0.05775\n",
      "3        1      4    0.09675\n",
      "4        1      5    0.14675\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "folder_path = \"./data\"\n",
    "file_names = [\"tag\", \"rating\", \"movie\", \"link\", \"genome_tags\", \"genome_scores\"]\n",
    "\n",
    "print(\"Columns in each data source:\")\n",
    "\n",
    "for file_name in file_names:\n",
    "    df = pd.read_csv(folder_path + \"/\" + file_name + \".csv\")\n",
    "    print(\"File name: \" + file_name)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3cbb5-a615-4164-9381-4c0617a3614d",
   "metadata": {},
   "source": [
    "I will use the following data for the 3 approaches, \n",
    "\n",
    "1. Collaborative (user based): movie rating data\n",
    "2. Collaborative (movie based): movie rating data\n",
    "3. Content based : genome scores data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983b44e6-a672-4b1a-88aa-5405ae761a09",
   "metadata": {},
   "source": [
    "#### Checking for missing or incomplete data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf9da42-0e61-4d97-a185-268a1bf50d70",
   "metadata": {},
   "source": [
    "##### Movie rating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "299fff5f-5095-4e78-9c19-465363b1106c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating            timestamp\n",
      "0       1        2     3.5  2005-04-02 23:53:47\n",
      "1       1       29     3.5  2005-04-02 23:31:16\n",
      "2       1       32     3.5  2005-04-02 23:33:39\n",
      "3       1       47     3.5  2005-04-02 23:32:07\n",
      "4       1       50     3.5  2005-04-02 23:29:40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = \"./data/rating.csv\"\n",
    "rating_df = pd.read_csv(data_path)\n",
    "print(rating_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d3344d-bcce-4045-8cfa-a9e98dab8fc1",
   "metadata": {},
   "source": [
    "Questions i'm concerned with:\n",
    "1. What is the total number of movies?\n",
    "2. What is the total number of users?\n",
    "3. What is the average number of movies rated by a user?\n",
    "4. What is the average number of ratings per movie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4053371-7154-4e97-979b-55afe5f4ee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId         138493\n",
      "movieId         26744\n",
      "rating             10\n",
      "timestamp    15351121\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(rating_df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a69bdc3b-1e57-412b-ba29-ec5f16555b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    30780.000000\n",
      "mean       125.001527\n",
      "std        194.073437\n",
      "min          1.000000\n",
      "25%         29.000000\n",
      "50%         60.000000\n",
      "75%        139.000000\n",
      "max       4354.000000\n",
      "Name: movieId, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "user_movie_count = rating_df.groupby('userId')['movieId'].nunique()\n",
    "print(user_movie_count.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ad5f22b-c89c-4f23-9991-a40b61328c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    26302.000000\n",
      "mean       146.283439\n",
      "std        592.830393\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          8.000000\n",
      "75%         44.000000\n",
      "max      14023.000000\n",
      "Name: userId, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "movie_user_count = rating_df.groupby('movieId')['userId'].nunique()\n",
    "print(movie_user_count.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b2fd91-c7a1-4f41-9c62-3727821f3afe",
   "metadata": {},
   "source": [
    "### Collaborative Filtering\n",
    "\n",
    "##### User-based Collaborative Filtering (CF):\n",
    "\n",
    "<b>Concept:</b> User-based CF identifies users with similar taste in movies (neighbors) and recommends movies those neighbors enjoyed but the target user hasn't seen yet. These neighbours can be identified through various methods based on the use case. <br/>\n",
    "One way to go about it is to use K-nearest neighbours based on adjusted cosine similarity. This would identify users who have rated similar movies with similar ratings and then see what else they liked to suggest to you. One potential problem here is that since we only look at a small subset of people around you, we might miss out on popular trends. For example, if Game of thrones comes out but people in the small subset haven't rated it highly, then if wouldn't get recommended. <br/>\n",
    "In order to also catch these kinds of trends it would make sense to see a larger set of users, one way to do this is to choose a miuch large k value in k nearest neibours which would effectively take into account a cluster of users similar to you. This would be equivalent to doing a kmeans algorithm to get this cluster. The predictions can be made using weighted average of the ratings of the users in your cluster, weighted by similarity scores. This would give more importance to the users more similar to you.\n",
    "\n",
    "<b>Similarity Calculation:</b> We can calculate pairwise similarity between users using adjusted cosine similarity. This measures how closely aligned their rating vectors are, considering the direction of their ratings\n",
    "\n",
    "<b>Considerations:</b>\n",
    "- We are using adjusted cosine since it's possible some users tend to rate enverything higher and some everything lower.\n",
    "- There exists a likely scenario that there isn't much overlap between the movies 2 people have rated. This is one of the major downsides of this kind of approach.\n",
    "\n",
    "  Although, a case can be made that users not having rated the same movies does carry some significance from case to case.\n",
    "\n",
    "  For example, if 2 users only have a Netflix subscription, it is likely that they haven't rated movies that are Hotstar exclusives. Moreoever, it would not make sense to receommend them movies exclusive to Hotstar.\n",
    "\n",
    "  Another example of the relevance of not rating the same movies would be if the languages of the movies is something they don't speak. English movie watchers would not have rated Japanese movies which should mean they have similar taste in a way.\n",
    "\n",
    "  Ultimately, it would really be based on <b>how the data was collected and and from which users</b>.\n",
    "\n",
    "##### New features we can consider:\n",
    "\n",
    "- <b>Time based importance:</b> We can add a term to add weight to more recent reviews since the older recommendations can be considered a little stale. This will basically be included in the similarity calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba38f81-d456-4331-abbb-ba229dddad54",
   "metadata": {},
   "source": [
    "#### User-based Collaborative Filtering (CF):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1106ba11-b292-41ac-b7ec-6fff54770a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000263"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rating_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "997e5ec0-e2c4-44ca-94a0-e48cfe5ecff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2015-03-31 06:40:02'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df['timestamp'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6010b315-00da-4bfd-8be5-eda3d5faf5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df['timestamp'] = pd.to_datetime(rating_df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf743c47-4a06-4774-94b3-f5dd3d18a5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>11</td>\n",
       "      <td>4226</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2011-01-12 01:35:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>11</td>\n",
       "      <td>5971</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2011-01-12 01:36:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>11</td>\n",
       "      <td>6291</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2011-01-12 01:35:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>11</td>\n",
       "      <td>7153</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2011-01-12 01:35:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>11</td>\n",
       "      <td>30707</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2011-01-12 01:36:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999317</th>\n",
       "      <td>138485</td>\n",
       "      <td>79132</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2012-09-04 03:12:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999601</th>\n",
       "      <td>138489</td>\n",
       "      <td>318</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2012-11-15 14:21:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999604</th>\n",
       "      <td>138489</td>\n",
       "      <td>858</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2012-11-15 14:21:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999605</th>\n",
       "      <td>138489</td>\n",
       "      <td>912</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2012-11-15 14:21:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999618</th>\n",
       "      <td>138489</td>\n",
       "      <td>2019</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2012-11-15 14:21:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>444457 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating           timestamp\n",
       "1175          11     4226     5.0 2011-01-12 01:35:59\n",
       "1231          11     5971     5.0 2011-01-12 01:36:41\n",
       "1239          11     6291     5.0 2011-01-12 01:35:13\n",
       "1267          11     7153     5.0 2011-01-12 01:35:32\n",
       "1315          11    30707     5.0 2011-01-12 01:36:16\n",
       "...          ...      ...     ...                 ...\n",
       "19999317  138485    79132     5.0 2012-09-04 03:12:39\n",
       "19999601  138489      318     5.0 2012-11-15 14:21:15\n",
       "19999604  138489      858     5.0 2012-11-15 14:21:18\n",
       "19999605  138489      912     5.0 2012-11-15 14:21:30\n",
       "19999618  138489     2019     5.0 2012-11-15 14:21:28\n",
       "\n",
       "[444457 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df[rating_df['rating'] == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dda6521f-95e3-4dad-9610-21d883d7d36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df['timestamp'] = pd.to_datetime(rating_df['timestamp'])\n",
    "rating_df = rating_df[rating_df['timestamp'].dt.year >= 2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5be9021-500b-426c-adc3-6ec9ff1d7b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId         30780\n",
      "movieId        26302\n",
      "rating            10\n",
      "timestamp    3777228\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(rating_df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cffcdbc-888d-4027-8268-5114acefb4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the rating_df into a dictionary reporesentation\n",
    "user_rating_dictionary = {}\n",
    "for _, row in rating_df.iterrows():\n",
    "    if row['userId'] not in user_rating_dictionary:\n",
    "        user_rating_dictionary[row['userId']] = {}\n",
    "    user_rating_dictionary[row['userId']][row['movieId']] = [row['rating'], row['timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5853ef8a-ead0-46e7-810d-62ecae581e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./data/user_rating_dictionary.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_rating_dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa4197e-0e1c-452d-bb5d-c920f8eb29a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/user_rating_dictionary.pkl\", \"rb\") as f:\n",
    "    user_rating_dictionary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dd36918-90e6-42d9-a065-79eebc299920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute similarity between 2 users\n",
    "def adjusted_cosine_similarity(user1_ratings, user2_ratings, min_ratings=7):\n",
    "    \"\"\"\n",
    "    Calculates the adjusted cosine similarity between two user rating dictionaries,\n",
    "    considering only movies rated by both users and enforcing a minimum rating threshold.\n",
    "    \n",
    "    Args:\n",
    "      user1_ratings: A dictionary representing user 1's ratings (movie ID as key, rating as value).\n",
    "      user2_ratings: A dictionary representing user 2's ratings (movie ID as key, rating as value).\n",
    "      min_ratings: Minimum number of movies required to be rated by both users for similarity calculation (default 1).\n",
    "    \n",
    "    Returns:\n",
    "      The adjusted cosine similarity between the two users, or 0 if the minimum rating threshold is not met or no movies are rated by both users.\n",
    "    \"\"\"\n",
    "    \n",
    "    intersection = set(user1_ratings.keys()) & set(user2_ratings.keys())  # Get common movies\n",
    "    if len(intersection) < min_ratings:\n",
    "        return 0  # Similarity is 0 if below minimum rating threshold\n",
    "    \n",
    "    if not intersection:\n",
    "        return 0  # No common movies, similarity is 0\n",
    "    \n",
    "    user1_avg = np.mean(list(user1_ratings[movie][0] for movie in intersection))  # Average rating for user 1 (using list comprehension)\n",
    "    user2_avg = np.mean(list(user2_ratings[movie][0] for movie in intersection))  # Average rating for user 2 (using list comprehension)\n",
    "\n",
    "    # Define a function to calculate freshness penalty (replace with your chosen approach)\n",
    "    def freshness_penalty(time_difference):\n",
    "        decay_rate = 0.01  # Adjust this parameter to control the penalty strength\n",
    "        time_difference_days = time_difference.days\n",
    "        penalty = 1 - decay_rate * time_difference_days\n",
    "        return max(penalty, 0)  # Ensure penalty is between 0 and 1\n",
    "    \n",
    "    # numerator = sum((user1_ratings[movie] - user1_avg) * (user2_ratings[movie] - user2_avg) for movie in intersection)\n",
    "    # denominator = np.sqrt(sum((user1_ratings[movie] - user1_avg)**2 for movie in intersection) * \n",
    "    #                      sum((user2_ratings[movie] - user2_avg)**2 for movie in intersection))\n",
    "\n",
    "    numerator = sum([(user1_ratings[movie][0] - user1_avg) * (user2_ratings[movie][0] - user2_avg) *\n",
    "                   freshness_penalty(user1_ratings[movie][1] - user2_ratings[movie][1]) for movie in intersection])\n",
    "    denominator = np.sqrt(sum((user1_ratings[movie][0] - user1_avg)**2 for movie in intersection) *\n",
    "                          sum((user2_ratings[movie][0] - user2_avg)**2 for movie in intersection))\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    \n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "142317eb-0a51-47a3-b8bd-ab2e992d24cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 35\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# You can observe the elbow point in the plot to determine the optimal k\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Example usage (replace with your actual data)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(user_rating_dictionary\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m---> 35\u001b[0m \u001b[43mkmeans_cosine_elbow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 12\u001b[0m, in \u001b[0;36mkmeans_cosine_elbow\u001b[1;34m(data, max_clusters)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data)):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i, \u001b[38;5;28mlen\u001b[39m(data)):  \u001b[38;5;66;03m# Fill upper triangular matrix for efficiency (avoid duplicates)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m         similarity_matrix[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43madjusted_cosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m         similarity_matrix[j, i] \u001b[38;5;241m=\u001b[39m similarity_matrix[i, j]  \u001b[38;5;66;03m# Fill lower triangular matrix for symmetry\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# List to store WCSS (Within-Cluster Sum of Squares) for different k values\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 24\u001b[0m, in \u001b[0;36madjusted_cosine_similarity\u001b[1;34m(user1_ratings, user2_ratings, min_ratings)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# No common movies, similarity is 0\u001b[39;00m\n\u001b[0;32m     23\u001b[0m user1_avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mlist\u001b[39m(user1_ratings[movie][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m movie \u001b[38;5;129;01min\u001b[39;00m intersection))  \u001b[38;5;66;03m# Average rating for user 1 (using list comprehension)\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m user2_avg \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muser2_ratings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmovie\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmovie\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mintersection\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Average rating for user 2 (using list comprehension)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Define a function to calculate freshness penalty (replace with your chosen approach)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfreshness_penalty\u001b[39m(time_difference):\n",
      "File \u001b[1;32mD:\\AiEngineer\\Projects\\PortfolioProjects\\MovieRecommendationSystem\\recommend_env\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3505\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\AiEngineer\\Projects\\PortfolioProjects\\MovieRecommendationSystem\\recommend_env\\Lib\\site-packages\\numpy\\core\\_methods.py:102\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mean\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 102\u001b[0m     arr \u001b[38;5;241m=\u001b[39m asanyarray(a)\n\u001b[0;32m    104\u001b[0m     is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     rcount \u001b[38;5;241m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Kmeas clustering using the cosine similarity\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def kmeans_cosine_elbow(data, max_clusters=10):\n",
    "    # Calculate cosine similarity matrix using your custom function\n",
    "    similarity_matrix = np.zeros((len(data), len(data)))  # Initialize similarity matrix\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i, len(data)):  # Fill upper triangular matrix for efficiency (avoid duplicates)\n",
    "            similarity_matrix[i, j] = adjusted_cosine_similarity(data[i], data[j])\n",
    "            similarity_matrix[j, i] = similarity_matrix[i, j]  # Fill lower triangular matrix for symmetry\n",
    "    \n",
    "    # List to store WCSS (Within-Cluster Sum of Squares) for different k values\n",
    "    wcss = []\n",
    "    for k in range(1, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)  # Set random state for reproducibility\n",
    "        kmeans.fit(similarity_matrix)\n",
    "        wcss.append(kmeans.inertia_)  # Inertia represents WCSS\n",
    "    \n",
    "    # Elbow plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, max_clusters + 1), wcss, marker='o', linestyle='-')\n",
    "    plt.xlabel(\"Number of clusters\")\n",
    "    plt.ylabel(\"WCSS\")\n",
    "    plt.title(\"Elbow Plot for KMeans with Cosine Similarity\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # You can observe the elbow point in the plot to determine the optimal k\n",
    "    \n",
    "# Example usage (replace with your actual data)\n",
    "data = list(user_rating_dictionary.values())\n",
    "kmeans_cosine_elbow(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3810a6-4d70-4ec1-958d-031412a20744",
   "metadata": {},
   "source": [
    "Note that although the clusters don't look all that great in terms of WCSS, our object of making them was to capture macro trends in the data.<br/> Also, since we are using similarity weighted predictions, it's okay in this case that the clusters aren't properly segregated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc19a948-e44b-4e01-bbc1-11416cc48bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def kmeans_clustering(data, optimal_k):\n",
    "    \"\"\"\n",
    "    Performs KMeans clustering with the specified k and visualizes the clusters.\n",
    "    \n",
    "    Args:\n",
    "      data: A numpy array representing the user rating dictionaries.\n",
    "      optimal_k: The chosen optimal number of clusters.\n",
    "    \"\"\"\n",
    "    # Calculate cosine similarity matrix using your custom function (assuming it's defined)\n",
    "    similarity_matrix = np.zeros((len(data), len(data)))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i, len(data)):\n",
    "            similarity_matrix[i, j] = adjusted_cosine_similarity(data[i], data[j])\n",
    "            similarity_matrix[j, i] = similarity_matrix[i, j]\n",
    "    \n",
    "    # Perform KMeans clustering with the chosen k\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "    kmeans.fit(similarity_matrix)\n",
    "    \n",
    "    # Get cluster labels for each data point\n",
    "    return kmeans.labels_, similarity_matrix\n",
    "\n",
    "# Create empty lists to store keys and values\n",
    "top_keys = []\n",
    "top_values = []\n",
    "\n",
    "# Loop through the dictionary and add key-value pairs\n",
    "for key, value in user_rating_dictionary.items():\n",
    "  # if len(top_keys) < 500:\n",
    "    top_keys.append(key)\n",
    "    top_values.append(value)\n",
    "\n",
    "# Example usage (replace with your actual data and optimal k\n",
    "optimal_k = 6  # Replace with your actual optimal k value\n",
    "\n",
    "cluster_labels, similarity_matrix = kmeans_clustering(top_values, optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f697e5a-5c93-4135-9192-f06c5d3b1c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./data/similarity_matrix.pkl\", \"wb\") as f:\n",
    "    pickle.dump(similarity_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583579c4-5529-4ecd-9ac7-15598d19b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/similarity_matrix.pkl', 'rb') as f:\n",
    "    loaded_similarity_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6c06360-4e89-42f4-9318-123c71653943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movie_rating_dict</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>{4226: [5.0, 2011-01-12 01:35:59], 5971: [5.0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>{186: [4.0, 2010-02-28 09:01:46], 912: [5.0, 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>{21: [3.5, 2010-07-01 05:54:26], 22: [4.0, 201...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>{1: [3.0, 2015-02-23 23:18:07], 110: [5.0, 201...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>{145: [3.5, 2011-06-07 01:33:55], 163: [3.0, 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId                                  movie_rating_dict  cluster_id\n",
       "0      11  {4226: [5.0, 2011-01-12 01:35:59], 5971: [5.0,...           1\n",
       "1      18  {186: [4.0, 2010-02-28 09:01:46], 912: [5.0, 2...           1\n",
       "2      25  {21: [3.5, 2010-07-01 05:54:26], 22: [4.0, 201...           1\n",
       "3      31  {1: [3.0, 2015-02-23 23:18:07], 110: [5.0, 201...           1\n",
       "4      36  {145: [3.5, 2011-06-07 01:33:55], 163: [3.0, 2...           1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# merge together, top_keys, top_values, and cluster_labels\n",
    "data_dict = {\"userId\": top_keys, \"movie_rating_dict\": top_values, \"cluster_id\": cluster_labels}\n",
    "# Create a DataFrame from the dictionary\n",
    "clustered_df = pd.DataFrame(data_dict)\n",
    "\n",
    "clustered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46d97bd-c606-468b-8d60-39321291b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./data/clustered_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clustered_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3ca7a-d3e7-40c6-93c7-c1879cc436c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/clustered_data.pkl', 'rb') as f:\n",
    "    clustered_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "415b33e2-6e76-4f0a-8e7b-4da77fbe7770",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ratings = {2:2, 29:4, 242:1, 6:4}\n",
    "# predicted_cluster = kmeans_model.predict(new_user_ratings)\n",
    "\n",
    "# Find most similar user in training data (assuming similarity scores are stored somewhere)\n",
    "most_similar_user_index = np.argmax(similarity_matrix, axis=0)  # Find index of max similarity\n",
    "# Predict cluster label based on most similar user's cluster\n",
    "predicted_cluster = clustered_df.loc[most_similar_user_index, 'cluster_id'].iloc[0]\n",
    "recommendations = {}\n",
    "\n",
    "# Need to recommend high rated movies from the same cluster.\n",
    "# Filter out all entries from a particular cluster\n",
    "single_cluster_df = clustered_df[clustered_df['cluster_id'] == predicted_cluster]\n",
    "\n",
    "# Create a priority list of the (on average) highest rated movies in that cluster\n",
    "# Need to create a dictionary from the rating values in that cluster.\n",
    "cluster_size = len(single_cluster_df)\n",
    "result_dict = {}\n",
    "for index, row in clustered_df.iterrows():\n",
    "    similarity_score = adjusted_cosine_similarity(row['movie_rating_dict'], new_user_ratings, min_ratings=1)\n",
    "    for movieId, rating in row['movie_rating_dict'].items():\n",
    "        if movieId not in result_dict:\n",
    "            result_dict[movieId] = {\n",
    "                \"sum_similarity_rating\": 0,\n",
    "                \"sum_similarity\": 0\n",
    "            }\n",
    "        result_dict[movieId][\"sum_similarity_rating\"] += similarity_score*rating\n",
    "        result_dict[movieId][\"sum_similarity\"] += similarity_score\n",
    "\n",
    "        if result_dict[movieId][\"sum_similarity\"] == 0:\n",
    "            net_score = 0\n",
    "        else:\n",
    "            net_score = result_dict[movieId][\"sum_similarity_rating\"]/result_dict[movieId][\"sum_similarity\"]\n",
    "        recommendations[movieId] = net_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d44832a7-1a1d-4f18-9944-3252cb51de56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[234, 3917, 1797, 762, 2688]\n"
     ]
    }
   ],
   "source": [
    "# Sort the dictionary by values (scores) in descending order\n",
    "sorted_movies = dict(sorted(recommendations.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Get the top 5 movie names (keys)\n",
    "top_5_movies = list(sorted_movies.keys())[:5]\n",
    "\n",
    "print(top_5_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85bd36de-571f-48ec-b519-672561b48ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n"
     ]
    }
   ],
   "source": [
    "# Get the movie names\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"./data/movie.csv\"\n",
    "movie_df = pd.read_csv(data_path)\n",
    "print(movie_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53f05282-22d4-48be-94c2-edd6a55eddff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forget Paris (1995)\n",
      "Snatch (2000)\n",
      "Quest for Camelot (1998)\n",
      "Spirits of the Dead (1968)\n",
      "Better Than Chocolate (1999)\n"
     ]
    }
   ],
   "source": [
    "movie_df = movie_df.set_index('movieId')\n",
    "for movie in top_5_movies:\n",
    "    print(movie_df.iloc[movie][\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ea2878-974a-4b3b-a4b7-bb29de66f293",
   "metadata": {},
   "source": [
    "### Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a87999eb-15de-4414-9869-a3b1821cebd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 13:54:49.317 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run D:\\AiEngineer\\Projects\\PortfolioProjects\\MovieRecommendationSystem\\recommend_env\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-05-27 13:54:49.317 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# Sample movie data (replace with your actual data source)\n",
    "movies = pd.DataFrame({\n",
    "    \"title\": [\"Movie A\", \"Movie B\", \"Movie C\", \"Movie D\", \"Movie E\"],\n",
    "    \"genre\": [\"Action\", \"Comedy\", \"Romance\", \"Sci-Fi\", \"Thriller\"]\n",
    "})\n",
    "\n",
    "# User input dictionary (initially empty)\n",
    "user_ratings = {}\n",
    "\n",
    "def recommend_movies(user_ratings, movies):\n",
    "  \"\"\"\n",
    "  Recommends movies based on cosine similarity between user ratings and movie data.\n",
    "\n",
    "  Args:\n",
    "      user_ratings: A dictionary storing user ratings for movie IDs (key) and ratings (value).\n",
    "      movies: A pandas DataFrame containing movie information (title, genre, etc.).\n",
    "\n",
    "  Returns:\n",
    "      A list of top N recommended movie titles.\n",
    "  \"\"\"\n",
    "\n",
    "  # Create a DataFrame from user ratings (assuming movie IDs are unique)\n",
    "  user_ratings_df = pd.DataFrame.from_dict(user_ratings, orient='index', columns=['rating'])\n",
    "\n",
    "  # Calculate cosine similarity between user ratings and movie data (assuming movie IDs are the same)\n",
    "  similarity_matrix = cosine_similarity(user_ratings_df, movies)\n",
    "\n",
    "  # Get average rating for each movie (optional, for filtering)\n",
    "  average_ratings = movies.groupby('title')['rating'].transform('mean')\n",
    "\n",
    "  # Select top N movies with high similarity and (optional) above average rating\n",
    "  N = 5  # Number of recommendations\n",
    "  recommendations = similarity_matrix.iloc[0].sort_values(ascending=False).head(N).index[similarity_matrix.iloc[0] > 0.5]  # Filter by minimum similarity threshold\n",
    "  recommendations = recommendations[recommendations.isin(average_ratings[average_ratings > user_ratings_df.iloc[0]['rating']].index)]  # Optional filtering by average rating\n",
    "\n",
    "  return list(recommendations)\n",
    "\n",
    "st.title(\"Movie Recommendation App\")\n",
    "\n",
    "# User input section\n",
    "movie_select = st.selectbox(\"Select a movie you've seen:\", movies[\"title\"].to_list())\n",
    "rating_select = st.slider(\"Rate the movie:\", 1, 5, 1)\n",
    "\n",
    "if st.button(\"Submit Rating\"):\n",
    "  user_ratings[movies[movies[\"title\"] == movie_select].iloc[0][\"title\"]] = rating_select\n",
    "\n",
    "# Recommendation section\n",
    "if user_ratings:\n",
    "  recommendations = recommend_movies(user_ratings, movies.copy())\n",
    "  st.subheader(\"Recommended Movies for You:\")\n",
    "  for movie in recommendations:\n",
    "    st.write(movie)\n",
    "else:\n",
    "  st.write(\"Rate some movies to get recommendations!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb92ed-e8ee-4aac-932b-9709c09b5772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
